## 高性能缓存系统

## 项目介绍
本项目使用多个页面替换策略实现一个线程安全的缓存系统：
- LRU：最近最久未使用
- LFU：最近不经常使用
- ARC：自适应替换
- Clock：时钟替换
  
对于LRU和LFU策略，在其基础的缓存策略上进行了相应的优化：

- LRU优化：
    - LRU-k：一定程度上防止热点数据被冷数据挤出容器而造成缓存污染等问题
    - LRU分片：对多线程下的高并发访问有性能上的优化

- LFU优化：
    - 引入最大平均访问频次：解决过去的热点数据最近一直没被访问，却仍占用缓存等问题
    - LFU分片：对多线程下的高并发访问有性能上的优化
  
未来还可能持续添加其他页面替换算法的实现，敬请期待
## 文件结构
- include：                包含各种缓存替换策略的实现头文件
    - CachePolicy.h：       缓存替换策略基类
    - LruCache.h：          LRU、LRU-k、HashLRU缓存替换策略实现
    - LfuCache.h：          LFU、HashLFU缓存替换策略实现 
    - ArcNode.h：           ARC缓存替换策略链表节点构建
    - ArcCache.h：          ARC缓存替换策略实现
    - ArcLruCache.h：       ARC-LRU部分缓存替换策略实现
    - ArcLfuCache.h：       ARC-LFU部分缓存替换策略实现
    - ClockCache.h：        Clock换内存替换策略实现
- test：                  测试代码
    - test0.cpp：           测试代码0
    - test1.cpp：           测试代码1
    - test2.cpp：           测试代码2
    - test3.cpp：           测试代码3
    - test4.cpp：           测试代码4
- image：                  测试结果图片        

## 测试环境 
- Ubuntu 20.04
- VsCode

当然，你也可以使用make进行编译，在test文件夹里写好了一个makefile文件，你只需要更改source对应的测试文件就好

进入test文件夹

``cd test``

清理原先的编译文件

``make clean``

编译

``make``

运行

``./test4``

也可以是其他测试文件，如test1，test2等。


## 测试结果
不同缓存策略缓存命中率与并发性测试对比结果详见image文件夹下
（ps: 该测试代码只是尽可能地模拟真实的访问场景，但是跟真实的场景仍存在一定差距，测试结果仅供参考。）

热点数据访问命中率测试：
| 测试缓存类型   | 命中次数 | 未命中次数 | 命中率   |
|---------------|----------|------------|----------|
| LRU Cache     | 3759     | 6241       | 37.59%   |
| LRU-K Cache   | 4008     | 5992       | 40.08%   |
| LFU Cache     | 4044     | 5956       | 40.44%   |
| Clock Cache   | 3908     | 6092       | 39.08%   |
| ARC Cache     | 6531     | 3469       | 65.31%   |

QPS数据说明，下列的QPS似乎都很大，实际场景中不会到达这样的量级，因为会有写回磁盘的操作或者其他行为等，我这里只是为了简便起见，就不进行写回脏数据的模拟行为了，当然你也可以添加写回操作

并发性测试1：
| 测试缓存类型   | 线程数 | 测试用时 (ms) | 总请求数 | QPS (queries/second)  |
|----------------|--------|---------------|----------|----------------------|
| LRU Cache      | 5      | 1098          | 500000   | 455373               |
| LFU Cache      | 5      | 3188          | 500000   | 156838               |
| ARC Cache      | 5      | 1192          | 500000   | 419463               |
| Hash LRU Cache | 5      | 978           | 500000   | 511247               |
| Hash LFU Cache | 5      | 1177          | 500000   | 424809               |

并发性测试2：
| 测试缓存          | 线程数 | 测试用时 | 总请求数 | QPS (queries/second) |
|-------------------|--------|----------|----------|--------------------|
| LRU Cache         | 10     | 37ms     | 10000    | 270270  |
| LFU Cache         | 10     | 80ms     | 10000    | 125000  |
| ARC Cache         | 10     | 53ms     | 10000    | 188679  |
| Hash LRU Cache    | 10     | 27ms     | 10000    | 370370  |
| Hash LFU Cache    | 10     | 33ms     | 10000    | 303030  |

并发性测试3：
| 测试缓存     | 线程数 | 测试用时 | 总请求数 | QPS (queries/second)|
|--------------|--------|----------|----------|--------------|
| LRU Cache    | 25     | 38ms     | 10000    | 263158  |
| LFU Cache    | 25     | 76ms     | 10000    | 131579  |
| Clock Cache  | 25     | 23ms     | 10000    | 434783  |
| ARC Cache    | 25     | 21ms     | 10000    | 476190  |
| Hash LRU Cache | 25    | 17ms     | 10000    | 588235  |
| Hash LFU Cache | 25    | 19ms     | 10000    | 526316  |

并发性测试4：
| 测试缓存          | 线程数 | 测试用时 | 总请求数 | QPS (queries/second) |
|-------------------|--------|----------|----------|--------------------|
| LRU Cache         | 50     | 44ms     | 10000    | 227273  |
| LFU Cache         | 50     | 89ms     | 10000    | 112360  |
| Clock Cache       | 50     | 24ms     | 10000    | 416667  |
| ARC Cache         | 50     | 32ms     | 10000    | 312500  |
| Hash LRU Cache    | 50     | 16ms     | 10000    | 625000  |
| Hash LFU Cache    | 50     | 23ms     | 10000    | 434783  |

Hash LRU 相对于 LRU 的性能提升约为 10%到100%不等，似乎线程数越多效果更为显著。
Hash LFU 相对于 LFU 的性能提升多数时候都保持100%以上，原因在于频率升级导致锁持有时间更长，锁竞争更明显。

分片LRU提升的效果较小甚至无提升的原因猜测：LRU的操作更轻量（基本都为O(1)复杂度），分片收益被哈希计算和分片管理开销部分抵消，或者是测试场景中键的访问集中在少数分片，分片内仍可能形成热点，锁竞争未显著缓解。

分片LFU提升的效果显著的原因猜测：LFU每次更新都要维护频率链表，频率处理导致锁持有的时间更久，而分片LFU将锁分散到多个分片，锁粒度更细，并行性大幅提升，显著减少了锁竞争，因此提升效果较为显著
